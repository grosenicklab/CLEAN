{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980d10ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ead4a83-08a1-4add-a4d5-a588bb7b6b81",
   "metadata": {},
   "source": [
    "# Load Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5f6ced-02c5-4bdb-ae8c-b878a8eb7a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify treatment raw file path\n",
    "data_path = '/Users/logang/Dropbox/GrosenickLab/data/accel_TMS_EEG/MDD/'\n",
    "\n",
    "data_folder = data_path+'subject9_m191_dlpfc_58/m191_dlpfc_day1/'\n",
    "filename = 'm191_dlpfc_day1_treatment_20230424_021417.mff'\n",
    "treatment_file_raw = os.path.join(data_folder, filename)\n",
    "treatment_raw = mne.io.read_raw_egi(treatment_file_raw, preload=True)\n",
    "\n",
    "def notch_and_hp(raw, notch_freqs, notch_widths, l_freq=1.0, h_freq=None, filter_type='fir'):\n",
    "    notch_freqs = np.array(notch_freqs)\n",
    "    notch_widths = np.asarray(notch_widths)\n",
    "    raw_notch = raw.copy().notch_filter(freqs=notch_freqs, notch_widths=None, verbose='warning')\n",
    "    raw_hp = raw_notch.filter(l_freq=l_freq, h_freq=h_freq, method=filter_type, verbose='warning')\n",
    "    return raw_hp\n",
    "\n",
    "notch_freqs = [60,120,180,240,300,360,400,420,460,480]\n",
    "notch_widths = None\n",
    "\n",
    "treatment_raw.info['bads'] = ['VREF']\n",
    "#treatment_filt = notch_and_hp(treatment_raw, l_freq=1.0, notch_freqs=notch_freqs, notch_widths=notch_widths)\n",
    "treatment_filt = treatment_raw.filter(l_freq=0.1, h_freq=None, method='fir', verbose='warning')\n",
    "#treatment_notch.info['bads'] = ['VREF']\n",
    "\n",
    "fig = treatment_raw.compute_psd().plot(show=True, exclude='bads')\n",
    "sns.despine()\n",
    "\n",
    "fig = treatment_filt.compute_psd().plot(show=True, exclude='bads')\n",
    "sns.despine()\n",
    "\n",
    "#treatment_filt.resample(200.0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca33077-4650-47d7-a72c-d62fc6eb01cd",
   "metadata": {},
   "source": [
    "### Plot Spectra and Epoch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec0fd54-5d5a-4438-b889-f0b38f109e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read DIN1 events for TMS data\n",
    "treatment_filt.info\n",
    "treatment_events = mne.find_events(treatment_filt, stim_channel = 'DIN1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139a1f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrum = treatment_filt.compute_psd()\n",
    "for average in (False, True):\n",
    "    spectrum.plot(average=average, dB=False, xscale=\"log\", picks=\"data\", exclude=\"bads\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eac122a-5b5b-4ed6-8ac6-cc73d497fe15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Epochs\n",
    "epochs = mne.Epochs(treatment_filt, treatment_events, tmin=-0.1, tmax=0.1, baseline=(0, 0), preload=True)\n",
    "print(epochs)  # 600 epochs created for Event ID '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24af97e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs.plot_image(combine=\"mean\")\n",
    "\n",
    "def get_epoch_sd(epochs):\n",
    "    return np.std(epochs,axis=0)\n",
    "\n",
    "epochs.plot_image(combine=get_epoch_sd)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605b28cc-2dec-408b-b1c9-6425273165fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = epochs.plot_image(picks=['E110'], vmin=-500, vmax=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305950de-733a-434f-83a1-ae55c3f090a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "evoked = epochs.average()\n",
    "evoked_se = epochs.standard_error()\n",
    "\n",
    "times = np.arange(0.0, 0.08, 0.005)\n",
    "evoked.plot_topomap(times)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18be1520",
   "metadata": {},
   "source": [
    "### Find iTBS pulse onsets without DINs (using peak finding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad40442e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.signal import find_peaks, find_peaks_cwt\n",
    "# from scipy import signal\n",
    "\n",
    "# def peak_find(data, fps=1000, method='wavelet', quantile_thresh=0.4, dist=0.25, prom_floor=1e-9, smooth_amount=0.5,\n",
    "#               band_lower=0.02, band_upper=1.0, wavelet_widths=[32.0], wavelet_snr=6.0):\n",
    "#     \"\"\"\n",
    "#     Arguments:\n",
    "#     - data: data time series\n",
    "#     - method: one of 'derivative', 'smooth', or 'wavelet'\n",
    "#     - quantile_thresh: sets level of threshold peaks must be above (for 'derivative' and 'smooth' methods)\n",
    "#     - dist: scales distance between peaks in units of frames per second (for 'derivative' and 'smooth' methods)\n",
    "#     - prom_floor: sets floor for prominence of peak threshold (for 'derivative' and 'smooth' methods)\n",
    "#     - smooth_amount: amount of smoothing used in 'smooth' method\n",
    "#     - band_lower: lower low pass band cutoff frequency (for 'derivative' method)\n",
    "#     - band_upper: upper low pass band cutoff frequency (for 'derivative' method)\n",
    "#     - wavelet_widths: width of wavelet(s) for 'wavelet' method\n",
    "#     - wavelet_snr: SNR for 'wavelet' method threshold\n",
    "#     Returns:\n",
    "#     - peak_idx: indices for peaks discovered\n",
    "\n",
    "#     \"\"\"\n",
    "#     if method == 'derivative':\n",
    "#         # set low pass filters\n",
    "#         lower = smooth_zerophase(data,amount = band_lower*(1.0/fps))\n",
    "#         upper = smooth_zerophase(data,amount = band_upper*(1.0/fps))\n",
    "\n",
    "#         # Get the smooth 2nd derivative of the squared difference between upper and lower low pass bands\n",
    "#         sq_diff = (upper-lower)**3\n",
    "#         neg_sm_2nd = -1*smooth_2nd_derivative(sq_diff,window_length=fps)\n",
    "\n",
    "#         # Find the maximum absolute deviation threshold at 95% CI and resulting max peaks for neg. 2nd derivative\n",
    "#         mad, thresh_idx = MAD_thresh(sq_diff+neg_sm_2nd,thresh=2.91)\n",
    "#         peak_idx = find_peaks(sq_diff+neg_sm_2nd, height=mad, distance=dist*fp_data.fps, prominence=(prom_floor,np.inf))[0]\n",
    "\n",
    "#     elif method == 'smooth':\n",
    "#         peak_detrend = smooth_zerophase(data, amount = (dr*smooth_amount/fps))\n",
    "#         peak_idx = find_peaks(peak_detrend, height=np.quantile(peak_detrend,[quantile_thresh])[0], distance=dist*fp_data.fps, prominence=(prom_floor,np.inf))[0]\n",
    "\n",
    "#     elif method == 'wavelet':\n",
    "#         peak_idx = find_peaks_cwt(data, widths=[w*fps for w in wavelet_widths], wavelet=signal.ricker, min_snr=wavelet_snr)\n",
    "#     else:\n",
    "#         raise ValueError('Specified method not available.')\n",
    "\n",
    "#     return peak_idx\n",
    "\n",
    "# def smooth_zerophase(x, amount = 0.05, order = 3):\n",
    "#     '''\n",
    "#     Smooths using a butterworth filter.  The filter is applied\n",
    "#     twice with filtfilt, once forward and once backwards.  This\n",
    "#     yield a zero phase (i.e. no lag) filter that is well suited\n",
    "#     to filtering time series.\n",
    "\n",
    "#     This is based directly on the filtfilt scipy recipe:\n",
    "\n",
    "#     http://wiki.scipy.org/Cookbook/FiltFilt\n",
    "#     Example:\n",
    "#     angles_left_smooth = smooth_zerophase(angles_left, 0.001, 1)\n",
    "#     angles_left_smoothed = angles_left - angles_left_smooth\n",
    "#     '''\n",
    "#     from scipy.signal import lfilter, lfilter_zi, filtfilt, butter\n",
    "\n",
    "#     # Create an order 3 lowpass butterworth filter.\n",
    "#     b, a = butter(order, amount)\n",
    "\n",
    "#     # Apply the filter to xn.  Use lfilter_zi to choose the initial condition\n",
    "#     # of the filter.\n",
    "#     zi = lfilter_zi(b, a)\n",
    "#     z, _ = lfilter(b, a, x, zi=zi*x[0])\n",
    "\n",
    "#     # Apply the filter again, to have a result filtered at an order\n",
    "#     # the same as filtfilt.\n",
    "#     z2, _ = lfilter(b, a, z, zi=zi*z[0])\n",
    "\n",
    "#     # Use filtfilt to apply the filter.\n",
    "#     y = filtfilt(b, a, x, padlen=int(0.1*len(x)),padtype='odd')\n",
    "#     return y\n",
    "\n",
    "# def MAD_thresh(data, thresh=2.91):\n",
    "#     MAD = np.median(np.abs(data - np.median(data)))\n",
    "#     thresh_idx = np.where(data > MAD*thresh)[0]\n",
    "#     return MAD, thresh_idx\n",
    "\n",
    "# def smooth_2nd_derivative(x,window_length=51): #why was window_length originally =51 here? but is =fps above\n",
    "#     return savgol_filter(x,window_length,polyorder=3,deriv=2,mode='nearest')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40060901-f714-4ceb-a2a6-1e8f5a33e0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.signal import savgol_filter\n",
    "# epoch_data = epochs.get_data()\n",
    "\n",
    "# tseries = np.squeeze(treatment_filt.pick(['E33']).get_data())\n",
    "\n",
    "# def find_tms_onset(time_series, thresh=0.004):\n",
    "#     time_series = savgol_filter(time_series,7,3,deriv=1)\n",
    "#     return np.where(time_series>thresh)[0]\n",
    "\n",
    "# peaks = peak_find(tseries)\n",
    "# plt.plot(tseries)\n",
    "\n",
    "# # for i in range(60):\n",
    "# #     plt.figure(figsize=(20,2))\n",
    "# #     vec = np.diff(np.mean(np.abs(epochs.pick(['E33']).get_data()),axis=1)[i*10,:])\n",
    "# #     peaks = peak_find(vec)\n",
    "# #     plt.axvline(x=peaks[0])\n",
    "# #     plt.plot(vec)\n",
    "# #     sns.despine()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c4617f",
   "metadata": {},
   "source": [
    "### Modeling the artifact with tensor decomposition (Tucker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe0af48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorly as tl\n",
    "from tensorly.decomposition import tucker, parafac\n",
    "\n",
    "epoch_data = epochs.get_data()[:,0:257,:]\n",
    "epoch_stim = epochs.get_data()[:,257:,:]\n",
    "\n",
    "import time\n",
    "tic = time.time()\n",
    "tucker_decomp = tucker(epoch_data,60)\n",
    "#cp_decomp = parafac(epoch_data,60)\n",
    "print(time.time()-tic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e85ca57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot tensor equivalent of singular values (diagonal of core tensor)\n",
    "def get_3dtensor_diag(tensor):\n",
    "    diag = []\n",
    "    for i in range(tensor.shape[0]):\n",
    "        diag.append(tensor[i,i,i])\n",
    "    return np.array(diag)\n",
    "tucker_diag = get_3dtensor_diag(tucker_decomp.core)\n",
    "plt.plot(np.log(np.abs(tucker_diag)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8f776c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(3):\n",
    "#     plt.figure(figsize=(5,5))\n",
    "#     plt.imshow(cp_decomp.factors[i],aspect='auto',interpolation='nearest')\n",
    "#     plt.title(\"CP \"+str(i))\n",
    "\n",
    "# Plot images of 2D factors\n",
    "for i in range(3):\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(tucker_decomp.factors[i],aspect='auto',interpolation='nearest')\n",
    "    plt.title(\"Tucker  \"+str(i))\n",
    "\n",
    "# Plot scalp maps and time series corresponding to tensor decomposition components\n",
    "for i in range(60):\n",
    "    fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(10,2))\n",
    "    ax2.plot(tucker_diag[i]*tucker_decomp.factors[2][:,i])\n",
    "    ax2.set_title(\"Component:\"+str(i))\n",
    "    mne.viz.plot_topomap(tucker_decomp.factors[1][:,i], pos=treatment_raw.info, axes=ax1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24df74f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero out first n components to try and remove artifact\n",
    "tucker_decomp.factors[2][:,0:38] = 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35098494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot channel over epochs pre artifact removal\n",
    "fig = epochs.plot_image(picks=['E110'], vmin=-500, vmax=500)\n",
    "\n",
    "# Plot channel over epochs post artifact removal\n",
    "tensor_cleaned = tensorly.tucker_to_tensor(tucker_decomp)\n",
    "tensor_cleaned = np.concatenate((tensor_cleaned,epoch_stim),axis=1)\n",
    "epochs_cleaned = mne.EpochsArray(tensor_cleaned,epochs.info)\n",
    "fig = epochs_cleaned.plot_image(picks=['E110'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5d0756",
   "metadata": {},
   "source": [
    "### Artifact removal with CEBRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ef7022",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cebra import CEBRA\n",
    "\n",
    "cebra_time_model = CEBRA(model_architecture='offset10-model',\n",
    "                        batch_size=1024,\n",
    "                        learning_rate=3e-4,\n",
    "                        temperature=1.0,\n",
    "                        output_dimension=250,\n",
    "                        max_iterations=10000,\n",
    "                        distance='cosine',\n",
    "                        conditional='time',\n",
    "                        device='cuda_if_available',\n",
    "                        verbose=True,\n",
    "                        time_offsets=500)\n",
    "cebra_time_model.fit(treatment_raw.get_data().T)\n",
    "#cebra_time_model.save(\"cebra_time_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2d0086",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cebra\n",
    "ax1 = plt.subplot(111, projection='3d')\n",
    "cebra_time = cebra_time_model.transform(treatment_raw.get_data().T)\n",
    "cebra.plot_embedding(ax=ax1, embedding=cebra_time, title='CEBRA-Time') #, cmap=cmap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd116273",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,2))\n",
    "for component_num in range(0,250,80):\n",
    "    plt.figure(figsize=(10,2))\n",
    "    plt.plot(cebra_time[105000:105500,component_num])\n",
    "    plt.title(\"CEBRA Component: \"+str(component_num))\n",
    "    plt.xlabel(\"Time Samples (1000 Hz)\")\n",
    "    plt.ylabel(\"A.U.\")\n",
    "    sns.despine()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c4a5f1",
   "metadata": {},
   "source": [
    "### Modeling the artifact with ICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5da97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import FastICA\n",
    "import scipy\n",
    "import pywt\n",
    "def wICA(ica, ICs, levels=7, wavelet='coif5', normalize=False, \n",
    "         trim_approx=False, thresholding='soft', verbose=True):\n",
    "    '''\n",
    "    Wavelet ICA thresholding. \n",
    "    Args:\n",
    "        ica: fitted ica object (currently only works with Sklearn's FastICA). TODO: add MNE options.\n",
    "        ICs: a numpy array of independent components with shape: (#time points, #components).\n",
    "        levels: number of wavelet levels.\n",
    "        wavelet: wavelet to use, defaults to Coiflet 5.\n",
    "        normalize: boolean, see pywt.swt documentation\n",
    "        trim_approx: boolean, see pywt.swt documentation\n",
    "        thresholding: 'hard' or 'soft',  should wavelet thresholding use a hard or soft threshold.\n",
    "        verbose: boolean flag for verbose printing.\n",
    "    Returns:\n",
    "        wICs: the wavelet thresholded ICs, leaving only large amplitude effects.\n",
    "        artifacts: the wICs ICA inverse transformed back to ambient data space, shape: (#time points, #channels). \n",
    "    '''\n",
    "    # Pad out the data to the correct length for wavelet thresholding\n",
    "    modulus = np.mod(ICs.shape[0],2**levels)\n",
    "    if modulus !=0:\n",
    "        extra = np.zeros((2**levels)-modulus)\n",
    "    if verbose:\n",
    "        print('  Data padded with ', str(len(extra)), ' additional values.')\n",
    "        print('  Wavelet thresholding with wavelet:', wavelet)\n",
    "    wavelet = pywt.Wavelet(wavelet)\n",
    "\n",
    "    # Iterate over independent components, thresholding each one using a stationary wavelet transform\n",
    "    # with soft thresholding. \n",
    "    print('  Fitting ICA for wavelet-ICA cleaning...')\n",
    "    wICs = []\n",
    "    for i in range(ICs.shape[1]):\n",
    "        if verbose:\n",
    "            print(\"  Thresholding IC#\",i)\n",
    "        sig = np.concatenate((ICs[:,i],extra))\n",
    "        thresh = ddencmp(sig, wavelet)\n",
    "        swc = pywt.swt(sig, wavelet, level=levels, start_level=0, trim_approx=trim_approx, norm=normalize)\n",
    "        y = pywt.threshold(swc, thresh, mode=thresholding, substitute=0)\n",
    "        wICs.append(pywt.iswt(y, wavelet, norm=normalize))\n",
    "    wICs = np.asarray(wICs)[:,0:ICs.shape[0]].T\n",
    "    \n",
    "    print(\"  Computing cleaned inverse transform...\")\n",
    "    artifacts = ica.inverse_transform(ICs)\n",
    "\n",
    "    #artifacts = np.dot(ICs, ica.mixing_.T)\n",
    "\n",
    "    #mean_tol = 1e-6\n",
    "    #if ica.whiten:\n",
    "    #    for i, mean in enumerate(ica.mean_):\n",
    "    #        print(\"  adding back mean \", str(i))\n",
    "    #        if np.abs(mean) > mean_tol:\n",
    "    #            artifacts[:,i] = artifacts[:,i] + mean\n",
    "\n",
    "    return wICs, artifacts\n",
    "\n",
    "def ddencmp(x, wavelet='db1', scale=2.0):\n",
    "    '''\n",
    "    Python recreation of MATLAB's ddencmp function for choosing wavelet threshold using \n",
    "    Donoho and Johnstone universal threshold scaled by a robust variance estimate.\n",
    "    Arg 'scale' allows adjusting the threshold more manually.\n",
    "\n",
    "    '''\n",
    "    n = len(x)\n",
    "    (cA, cD)  = pywt.dwt(x,wavelet)\n",
    "    noiselev = np.median(np.abs(cD))/0.6745\n",
    "    thresh = np.sqrt(2*np.log(len(x)))*noiselev*scale\n",
    "    return thresh\n",
    "\n",
    "ica = FastICA(n_components=250, whiten=\"arbitrary-variance\")\n",
    "ica.fit(treatment_raw.get_data().T)  \n",
    "ICs = ica.fit_transform(treatment_raw.get_data().T)\n",
    "wICs, artifacts = wICA(ica, ICs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e0ce45",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned = treatment_filt.get_data() - artifacts.T\n",
    "cleaned.min(), cleaned.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390379a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned = treatment_filt.get_data() - artifacts.T\n",
    "\n",
    "wICA_artifact_raw = mne.io.RawArray(artifacts.T,treatment_filt.info)\n",
    "wICA_artifact_epochs = mne.Epochs(wICA_artifact_raw, treatment_events, tmin=-0.1, tmax=0.1, baseline=(0, 0))\n",
    "fig = wICA_artifact_epochs.plot_image(picks=['E110'], vmin=-500, vmax=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057d5603",
   "metadata": {},
   "outputs": [],
   "source": [
    "wICA_cleaned_raw = mne.io.RawArray(cleaned, treatment_raw.info)\n",
    "wICA_cleaned_epochs = mne.Epochs(wICA_cleaned_raw, treatment_events, tmin=-0.1, tmax=0.1, baseline=(0, 0))\n",
    "fig = wICA_cleaned_epochs.plot_image(picks=['E110'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7dccc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,2))\n",
    "for component_num in range(0,250,80):\n",
    "    plt.figure(figsize=(10,2))\n",
    "    plt.plot(ICs[105000:105500,component_num])\n",
    "    plt.title(\"ICA Component: \"+str(component_num))\n",
    "    plt.xlabel(\"Time Samples (1000 Hz)\")\n",
    "    plt.ylabel(\"A.U.\")\n",
    "    sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b37d76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
